def agent(prompt, system=None, model="gpt-4o", temperature=0.7, api_key=None, base_url=None, tools=None, tool_handlers=None, max_iterations=10, stream=False):
    """
    Call an LLM with optional tool/function calling support.

    Args:
        prompt: The user message to send
        system: Optional system prompt
        model: Model name (default: gpt-4o). Use "claude-*" for Anthropic models
        temperature: Sampling temperature (default: 0.7)
        api_key: API key (defaults to OPENAI_API_KEY or ANTHROPIC_API_KEY env var)
        base_url: Custom API endpoint for OpenAI-compatible APIs (Ollama, Groq, Together, etc.)
        tools: List of tool definitions for function calling
        tool_handlers: Dict mapping tool names to handler functions
        max_iterations: Max agentic loop iterations (default: 10)
        stream: If True, return a generator that yields tokens (default: False)

    Returns:
        If stream=False: Dict with "content", "model", "tokens", and optionally "tool_calls"
        If stream=True: Generator that yields string chunks.

    Examples:
        # Non-streaming
        response = agent("What is 2 + 2?")
        print(response["content"])

        # Streaming
        for chunk in agent("Write a poem", stream=True):
            print(chunk, end="")
        print()
    """
    is_anthropic = model.startswith("claude") and base_url == None

    if stream:
        if is_anthropic:
            return _stream_anthropic(prompt, system, model, temperature, api_key)
        else:
            url = base_url if base_url else "https://api.openai.com/v1"
            return _stream_openai(prompt, system, model, temperature, api_key, url)

    if is_anthropic:
        return _call_anthropic(prompt, system, model, temperature, api_key, tools, tool_handlers, max_iterations)
    else:
        url = base_url if base_url else "https://api.openai.com/v1"
        return _call_openai(prompt, system, model, temperature, api_key, url, tools, tool_handlers, max_iterations)


def _http_request_sse(method, url, headers, body, extract_content):
    """
    Make an HTTP request and parse SSE (Server-Sent Events) response.

    Args:
        method: HTTP method
        url: Request URL
        headers: Request headers
        body: Request body (will be JSON encoded)
        extract_content: Function that takes parsed JSON data and returns content string or None

    Yields:
        Content strings extracted from SSE events
    """
    partial = ""
    for chunk in http_request(method, url, headers=headers, body=json_encode(body), stream=True):
        lines = (partial + chunk).split("\n")
        partial = lines[-1]

        for line in lines[:-1]:
            line = line.strip()
            if line == "" or line == "data: [DONE]":
                continue
            if line.startswith("data: "):
                data = json_decode(line[6:])
                content = extract_content(data)
                if content:
                    yield content


def _strip_trailing_slash(s):
    if s.endswith("/"):
        return s[:-1]
    return s


def _stream_openai(prompt, system, model, temperature, api_key, base_url):
    key = api_key if api_key else env("OPENAI_API_KEY")
    endpoint = _strip_trailing_slash(base_url) + "/chat/completions"

    messages = []
    if system:
        messages.append({"role": "system", "content": system})
    messages.append({"role": "user", "content": prompt})

    body = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "stream": True
    }

    headers = {"Content-Type": "application/json"}
    if key:
        headers["Authorization"] = "Bearer " + key

    def extract(data):
        if "choices" in data and len(data["choices"]) > 0:
            delta = data["choices"][0].get("delta", {})
            return delta.get("content", "")
        return None

    for chunk in _http_request_sse("POST", endpoint, headers, body, extract):
        yield chunk


def _stream_anthropic(prompt, system, model, temperature, api_key):
    key = api_key if api_key else env("ANTHROPIC_API_KEY")
    endpoint = "https://api.anthropic.com/v1/messages"

    messages = [{"role": "user", "content": prompt}]

    body = {
        "model": model,
        "max_tokens": 4096,
        "messages": messages,
        "temperature": temperature,
        "stream": True
    }
    if system:
        body["system"] = system

    headers = {
        "Content-Type": "application/json",
        "x-api-key": key,
        "anthropic-version": "2023-06-01"
    }

    def extract(data):
        if data.get("type") == "content_block_delta":
            delta = data.get("delta", {})
            return delta.get("text", "")
        return None

    for chunk in _http_request_sse("POST", endpoint, headers, body, extract):
        yield chunk


def _call_openai(prompt, system, model, temperature, api_key, base_url, tools, tool_handlers, max_iterations):
    key = api_key if api_key else env("OPENAI_API_KEY")
    endpoint = _strip_trailing_slash(base_url) + "/chat/completions"

    messages = []
    if system:
        messages.append({"role": "system", "content": system})
    messages.append({"role": "user", "content": prompt})

    openai_tools = None
    if tools:
        openai_tools = [
            {
                "type": "function",
                "function": {
                    "name": t["name"],
                    "description": t["description"],
                    "parameters": t["parameters"]
                }
            }
            for t in tools
        ]

    all_tool_calls = []
    total_tokens = {"prompt": 0, "completion": 0, "total": 0}
    final_content = ""

    headers = {"Content-Type": "application/json"}
    if key:
        headers["Authorization"] = "Bearer " + key

    for i in range(max_iterations):
        body = {
            "model": model,
            "messages": messages,
            "temperature": temperature
        }
        if openai_tools:
            body["tools"] = openai_tools

        resp = http_request("POST", endpoint, headers=headers, json=body)
        data = json.decode(resp.body)

        if "usage" in data:
            total_tokens["prompt"] += data["usage"]["prompt_tokens"]
            total_tokens["completion"] += data["usage"]["completion_tokens"]
            total_tokens["total"] += data["usage"]["total_tokens"]

        choice = data["choices"][0]
        msg = choice["message"]

        if "tool_calls" in msg and msg["tool_calls"]:
            messages.append(msg)

            for tc in msg["tool_calls"]:
                fn_name = tc["function"]["name"]
                fn_args = json.decode(tc["function"]["arguments"])

                if tool_handlers and fn_name in tool_handlers:
                    result = tool_handlers[fn_name](**fn_args)
                else:
                    result = {"error": "No handler for tool: " + fn_name}

                all_tool_calls.append({
                    "name": fn_name,
                    "arguments": fn_args,
                    "result": result
                })

                messages.append({
                    "role": "tool",
                    "tool_call_id": tc["id"],
                    "content": json.encode(result)
                })
        else:
            final_content = msg["content"] if msg["content"] else ""
            break

    result = {
        "content": final_content,
        "model": model,
        "tokens": total_tokens
    }
    if all_tool_calls:
        result["tool_calls"] = all_tool_calls
    return result


def _call_anthropic(prompt, system, model, temperature, api_key, tools, tool_handlers, max_iterations):
    key = api_key if api_key else env("ANTHROPIC_API_KEY")
    endpoint = "https://api.anthropic.com/v1/messages"

    messages = [{"role": "user", "content": prompt}]

    anthropic_tools = None
    if tools:
        anthropic_tools = [
            {
                "name": t["name"],
                "description": t["description"],
                "input_schema": t["parameters"]
            }
            for t in tools
        ]

    all_tool_calls = []
    total_tokens = {"prompt": 0, "completion": 0, "total": 0}
    final_content = ""

    headers = {
        "Content-Type": "application/json",
        "x-api-key": key,
        "anthropic-version": "2023-06-01"
    }

    for i in range(max_iterations):
        body = {
            "model": model,
            "max_tokens": 4096,
            "messages": messages,
            "temperature": temperature
        }
        if system:
            body["system"] = system
        if anthropic_tools:
            body["tools"] = anthropic_tools

        resp = http_request("POST", endpoint, headers=headers, json=body)
        data = json.decode(resp.body)

        if "usage" in data:
            total_tokens["prompt"] += data["usage"]["input_tokens"]
            total_tokens["completion"] += data["usage"]["output_tokens"]
            total_tokens["total"] = total_tokens["prompt"] + total_tokens["completion"]

        has_tool_use = False
        tool_results = []
        assistant_content = []

        for block in data["content"]:
            if block["type"] == "text":
                final_content = block["text"]
                assistant_content.append(block)
            elif block["type"] == "tool_use":
                has_tool_use = True
                assistant_content.append(block)

                fn_name = block["name"]
                fn_args = block["input"]

                if tool_handlers and fn_name in tool_handlers:
                    result = tool_handlers[fn_name](**fn_args)
                else:
                    result = {"error": "No handler for tool: " + fn_name}

                all_tool_calls.append({
                    "name": fn_name,
                    "arguments": fn_args,
                    "result": result
                })

                tool_results.append({
                    "type": "tool_result",
                    "tool_use_id": block["id"],
                    "content": json.encode(result)
                })

        if has_tool_use:
            messages.append({"role": "assistant", "content": assistant_content})
            messages.append({"role": "user", "content": tool_results})
        else:
            break

    result = {
        "content": final_content,
        "model": model,
        "tokens": total_tokens
    }
    if all_tool_calls:
        result["tool_calls"] = all_tool_calls
    return result
